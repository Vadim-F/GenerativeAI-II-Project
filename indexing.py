# indexing.py ‚Äî –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ ChromaDB —Å persistence

import os
from langchain_community.vectorstores import Chroma
# from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from dotenv import load_dotenv

# üîê –ó–∞–≥—Ä—É–∑–∫–∞ API-–∫–ª—é—á–µ–π
load_dotenv()

# üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, –æ–Ω –ª–µ–∂–∏—Ç –≤ .txt)
with open("./data/brain_article.txt", "r", encoding="cp1252") as file:
    raw_text = file.read()

# üîπ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100,
    length_function=len,
    separators=["\n\n", "\n", ".", " "]
)
chunks = text_splitter.split_text(raw_text)

# üß± –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∞–Ω–∫–∏ –≤ –æ–±—ä–µ–∫—Ç—ã Document —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
source_metadata = {
    "source": "newatlas.com",
    "date": "2025-03-03",
    "title": "World's first Synthetic Biological Intelligence runs on living human cells",
    "author": "Bronwyn Thompson"
}
documents = [Document(page_content=chunk, metadata=source_metadata) for chunk in chunks]

# üß† –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
# embedding_model = OpenAIEmbeddings()


# –°–æ–∑–¥–∞—ë–º ChromaDB —Å persistence
vectorstore = Chroma(persist_directory="chroma_store", embedding_function=embedding_model)

# ‚ûï –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
vectorstore.add_documents(documents)

# üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å –Ω–∞ –¥–∏—Å–∫
vectorstore.persist()

print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(documents)} —á–∞–Ω–∫–æ–≤.")
